## Delhi Traffic Density Prediction

This is a simple machine learning project designed to predict traffic density in Delhi. If you are interested in traffic analysis, data science, or machine learning, you can find good examples here.

## About the Dataset

The dataset used in this project was obtained from **Kaggle**. It contains real data about trips between different areas in Delhi city.

**Dataset link**: You can search on Kaggle with keywords like "Delhi Traffic" or similar terms.

### Columns in the Dataset:
- **Trip_ID**: Unique identifier for each trip
- **start_area**: Starting point (e.g., Vasant Kunj, Rohini)
- **end_area**: Destination point (e.g., Kalkaji, Dwarka)
- **distance_km**: Trip distance (kilometers)
- **time_of_day**: Time of day (Morning Peak, Afternoon, Evening Peak, Night)
- **day_of_week**: Weekday or weekend (Weekday, Weekend)
- **weather_condition**: Weather condition (Clear, Rain, Fog, Heatwave)
- **traffic_density_level**: Traffic density level - **TARGET VARIABLE** (Low, Medium, High, Very High)
- **road_type**: Road type (Main Road, Highway, Inner Road)
- **average_speed_kmph**: Average speed (km/hour)

## Project Purpose

To put it simply: With the data we have (distance, weather, time, road type, etc.), we are trying to predict **how dense the traffic will be**.

For example: When we say "a 15 km road, in rainy weather, during morning peak hours, on a main road," the model tells us "In this situation, traffic will probably be HIGH (dense)."

## Files

There are 3 main Python files in the project:

### 1. `wwdelhi_scaler.py` - Main Model File

**What does it do?**
- Loads the dataset (`wwdelhi_traffic.csv`)
- Cleans and prepares the data
- Trains a **Logistic Regression** model
- Measures model performance (accuracy, confusion matrix)
- Makes predictions for a new trip

**Why Logistic Regression?**
As written in the comments at the end of the file: "We used logistic regression here because we are trying to answer the question 'is there traffic or not?'" Actually, this is a multi-class classification (4 categories: Low, Medium, High, Very High), but the logic is simple: we categorize.

**Important techniques:**
- **Dummy Variables**: Converts categorical variables (weather, time of day) to numerical form
- **StandardScaler**: Normalizes numerical values (distance, speed) - this is very important!
- **Train-Test Split**: 80% of data for training, 20% for testing
- **Cross-Validation**: Overfitting control with 5-fold cross-validation

**Outputs:**
```
Train Accuracy: 90%
Test Accuracy: 88%
5-Fold CV Accuracy: 87%
```

If the difference between train and test accuracy is more than 10%, it gives a warning (meaning there is overfitting).

**What happens in the code step by step:**
1. Read the CSV file
2. Check for missing values (there are none, but checking is essential!)
3. Group rare weather conditions as 'Other' (overfitting prevention)
4. Convert categorical columns to dummy variables
5. Convert target variable (traffic_density_level) to numerical: Low=0, Medium=1, High=2, Very High=3
6. Split data into train-test sets
7. Scale numerical columns (distance, speed)
8. Train the model
9. Measure performance
10. Make a prediction on a new example and show probabilities

### 2. `ww-p-value-delhi.py` - Statistical Analysis

**What does it do?**
- Uses **Ordered Logit Model** (statsmodels library)
- Shows p-values (which variables are statistically significant? Greater or less than 0.05?)
- Provides summary output (coefficients, standard errors, z-scores)

**When is it used?**
- If you want to scientifically see which factors really affect traffic
- If you need statistical results for an academic report/thesis
- If you want to interpret model coefficients

**What is the difference?**
- `wwdelhi_scaler.py` â†’ For practical prediction (accuracy matters)
- `ww-p-value-delhi.py` â†’ For statistical significance (which variable is important?)

### 3. `testing.py` - Test the Model

**What does it do?**
- Imports the trained model (from `wwdelhi_scaler` module)
- Creates a new sample data
- Makes a prediction

**Example usage:**
```python
new_trip = pd.DataFrame({
    'distance_km': [15.5],              # 15.5 km road
    'average_speed_kmph': [25.0],       # Average 25 km/h speed
    'weather_condition': ['Rain'],      # Rainy weather
    'time_of_day': ['Morning Peak'],    # Morning peak time
    'day_of_week': ['Weekday'],         # Weekday
    'road_type': ['Main Road']          # Main road
})
```

**Output:**
```
Prediction: High

Probabilities:
  Low: 5.23%
  Medium: 18.67%
  High: 61.45%
  Very High: 14.65%
```

The model says: "Under these conditions, traffic will be HIGH (dense) with a 61% probability!"

## How to Use?

### Requirements

```bash
pip install pandas numpy scikit-learn statsmodels
```

### Step 1: Download the dataset
Download the Delhi traffic dataset from Kaggle and save it as `wwdelhi_traffic.csv`.

### Step 2: Run the main model
```bash
python wwdelhi_scaler.py
```

This command:
- Trains the model
- Shows performance metrics
- Makes a sample prediction

### Step 3: Make your own prediction
```bash
python testing.py
```

Or change the values in `testing.py` to test your own scenarios!

### Step 4 (Optional): Statistical analysis
```bash
python ww-p-value-delhi.py
```

To see p-values and coefficients.

## Technical Details

### Data Preprocessing

**1. Categorical Variables â†’ Dummy Variables**
```python
# Example: weather_condition
# ['Clear', 'Rain', 'Fog'] 
# Converts to â†’
# weather_condition_Rain: 0 or 1
# weather_condition_Fog: 0 or 1
# (Clear: both are 0 - reference category)
```

**2. Numerical Variables â†’ Scaling**
```python
# Distance: ranges from 2.15 km to 26.64 km
# Speed: ranges from 7.6 km/h to 68.5 km/h
# Standardize them: mean=0, std=1
```

**Why?** Logistic Regression is sensitive to distances. The difference between 20 km and 40 km needs to be normalized for the model to work correctly.

### Model Evaluation

**Confusion Matrix** - Shows how well the model works:
```
              Prediction
Actual    Low  Med  High  VHigh
Low       [120  10   2     0  ]
Medium    [ 15  95  18     1  ]
High      [  3  22  88     5  ]
Very High [  1   2  12    45  ]
```

Each row: actual value
Each column: model's prediction

**Classification Report** - Detailed metrics:
- **Precision**: Of the places the model says "High", how many are actually High?
- **Recall**: Of the actual Highs, how many did it catch?
- **F1-Score**: Harmonic mean of Precision and Recall

### Overfitting Control

```python
if train_acc - test_acc > 0.10:
    print("WARNING: Overfitting detected.")
```

If it is very successful on training data but poor on test data â†’ it means the model memorized rather than generalized!

**Solutions:**
- Collect more data
- Reduce the number of features
- Add regularization (L1, L2)
- Use cross-validation (we already do!)

## Tips and Notes

1. **Rare categories**
   ```python
   rare_weather = df['weather_condition'].value_counts()[
       df['weather_condition'].value_counts() < 5
   ].index
   ```
   We make weather conditions with fewer than 5 examples 'Other'. Why? Because the model cannot learn with 3-4 examples, it only memorizes.

2. **Pipeline usage**
   ```python
   model = Pipeline([
       ('preprocessor', preprocessor),
       ('classifier', LogisticRegression())
   ])
   ```
   This is a very clean approach! First preprocessing, then model - everything in one object.

3. **Be careful when making predictions for new data**
   ```python
   # Add columns that were not in training
   for col in X_train.columns:
       if col not in new_trip.columns:
           new_trip[col] = 0
   
   # Arrange columns in the same order. I had a lot of problems here
   new_trip = new_trip[X_train.columns]
   ```
   This is VERY important! Otherwise, the model will give an error.

## Learning Resources

If you want to learn more about these topics:

- **Pandas**: Data manipulation
- **Scikit-learn**: Machine learning
- **Logistic Regression**: Classification algorithm
- **Feature Engineering**: Variable engineering
- **Cross-Validation**: Model validation techniques
- **Confusion Matrix**: Model evaluation

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.




TÃœRKÃ‡E


# Delhi Trafik YoÄŸunluÄŸu Tahmini 

Merhaba! Bu proje Delhi'deki trafik yoÄŸunluÄŸunu tahmin etmek iÃ§in hazÄ±rlanmÄ±ÅŸ basit bir makine Ã¶ÄŸrenmesi projesidir. EÄŸer trafik analizi, veri bilimi veya makine Ã¶ÄŸrenmesiyle ilgileniyorsan, buradan gÃ¼zel Ã¶rnekler bulabilirsin!

## Veri Seti HakkÄ±nda

Bu projede kullanÄ±lan veri seti **Kaggle**'dan alÄ±nmÄ±ÅŸtÄ±r. Delhi ÅŸehrindeki farklÄ± bÃ¶lgeler arasÄ±ndaki yolculuklarÄ± iÃ§eren gerÃ§ek verilerdir.

**Veri seti linki**: Kaggle'da "Delhi Traffic" veya benzeri anahtar kelimelerle aratabilirsiniz.

### Veri Setindeki Kolonlar:
- **Trip_ID**: Her yolculuÄŸun benzersiz kimliÄŸi
- **start_area**: BaÅŸlangÄ±Ã§ noktasÄ± (Ã¶rn: Vasant Kunj, Rohini)
- **end_area**: VarÄ±ÅŸ noktasÄ± (Ã¶rn: Kalkaji, Dwarka)
- **distance_km**: Yolculuk mesafesi (kilometre)
- **time_of_day**: GÃ¼nÃ¼n hangi saati (Morning Peak, Afternoon, Evening Peak, Night)
- **day_of_week**: Hafta iÃ§i mi hafta sonu mu (Weekday, Weekend)
- **weather_condition**: Hava durumu (Clear, Rain, Fog, Heatwave)
- **traffic_density_level**: Trafik yoÄŸunluÄŸu seviyesi - **TAHMÄ°N EDÄ°LECEK DEÄER** (Low, Medium, High, Very High)
- **road_type**: Yol tipi (Main Road, Highway, Inner Road)
- **average_speed_kmph**: Ortalama hÄ±z (km/saat)

## Proje AmacÄ±

BasitÃ§e sÃ¶ylemek gerekirse: Elimizdeki verilerle (mesafe, hava durumu, saat, yol tipi vb.) **trafiÄŸin ne kadar yoÄŸun olacaÄŸÄ±nÄ±** tahmin etmeye Ã§alÄ±ÅŸÄ±yoruz.

Ã–rneÄŸin: "15 km'lik bir yol, yaÄŸmurlu havada, sabah yoÄŸun saatlerinde, ana yoldan gidilecek" dediÄŸimizde model bize "Bu durumda trafik muhtemelen HIGH (yoÄŸun) olacak" diyor.

## ğŸ“‚ Dosyalar

Projede 3 ana Python dosyasÄ± var:

### 1. `wwdelhi_scaler.py` - Ana Model DosyasÄ±

**Ne yapÄ±yor?**
- Veri setini yÃ¼klÃ¼yor (`wwdelhi_traffic.csv`)
- Verileri temizliyor ve hazÄ±rlÄ±yor
- **Logistic Regression** modeli eÄŸitiyor
- Model performansÄ±nÄ± Ã¶lÃ§Ã¼yor (accuracy, confusion matrix)
- Yeni bir yolculuk iÃ§in tahmin yapÄ±yor

**Neden Logistic Regression?**
DosyanÄ±n sonundaki yorumlarda yazÄ±yor: "Burada trafik var mÄ± yok mu sorusuna cevap aradÄ±ÄŸÄ±mÄ±z iÃ§in logistic regression kullandÄ±k." AslÄ±nda bu Ã§ok sÄ±nÄ±flÄ± bir sÄ±nÄ±flandÄ±rma (4 kategori: Low, Medium, High, Very High), ama mantÄ±k basit: kategorilere ayÄ±rÄ±yoruz.

**Ã–nemli teknikler:**
- **Dummy Variables**: Kategorik deÄŸiÅŸkenleri (hava durumu, gÃ¼nÃ¼n saati) sayÄ±sal hale getiriyor
- **StandardScaler**: SayÄ±sal deÄŸerleri (mesafe, hÄ±z) normalize ediyor - bu Ã§ok Ã¶nemli!
- **Train-Test Split**: Verinin %80'i eÄŸitim, %20'si test iÃ§in
- **Cross-Validation**: 5 katlÄ± crossvalidation ile overfitting kontrolÃ¼

**Ã‡Ä±ktÄ±lar:**
```
Train Accuracy: ~%90
Test Accuracy: ~%88
5-Fold CV Accuracy: ~%87
```

EÄŸer train ve test accuracy arasÄ±ndaki fark %10'dan fazlaysa âš ï¸ uyarÄ± veriyor (overfitting var demektir).

**Kodda ne oluyor adÄ±m adÄ±m:**
1. CSV dosyasÄ±nÄ± oku
2. Eksik deÄŸerleri kontrol et (yok ama kontrol ÅŸart!)
3. Nadir gÃ¶rÃ¼len hava durumlarÄ±nÄ± 'Other' olarak grupla (overfitting Ã¶nlemi)
4. Kategorik kolonlarÄ± dummy deÄŸiÅŸkenlere Ã§evir
5. Hedef deÄŸiÅŸkeni (traffic_density_level) sayÄ±sal hale getir: Low=0, Medium=1, High=2, Very High=3
6. Veriyi train-test olarak ayÄ±r
7. SayÄ±sal kolonlarÄ± (mesafe, hÄ±z) Ã¶lÃ§eklendir
8. Modeli eÄŸit
9. PerformansÄ± Ã¶lÃ§
10. Yeni bir Ã¶rnek Ã¼zerinde tahmin yap ve olasÄ±lÄ±klarÄ± gÃ¶ster

### 2. `ww-p-value-delhi.py` - Ä°statistiksel Analiz

**Ne yapÄ±yor?**
- **Ordered Logit Model** kullanÄ±yor (statsmodels kÃ¼tÃ¼phanesi)
- P-deÄŸerlerini gÃ¶steriyor (hangi deÄŸiÅŸkenler istatistiksel olarak anlamlÄ±? 0.05'ten bÃ¼yÃ¼k mÃ¼ kÃ¼Ã§Ã¼k mÃ¼?)
- Summary Ã§Ä±ktÄ±sÄ± veriyor (katsayÄ±lar, standart hatalar, z-skorlarÄ±)

**Ne zaman kullanÄ±lÄ±r?**
- Hangi faktÃ¶rlerin trafiÄŸi gerÃ§ekten etkilediÄŸini bilimsel olarak gÃ¶rmek istersen
- Akademik bir rapor/tez iÃ§in istatistiksel sonuÃ§lara ihtiyacÄ±n varsa
- Model katsayÄ±larÄ±nÄ± yorumlamak istersen

**Fark nedir?**
- `wwdelhi_scaler.py` â†’ Pratik tahmin iÃ§in (accuracy Ã¶nemli)
- `ww-p-value-delhi.py` â†’ Ä°statistiksel anlam iÃ§in (hangi deÄŸiÅŸken Ã¶nemli?)

### 3. `testing.py` - Modeli Test Et

**Ne yapÄ±yor?**
- EÄŸitilmiÅŸ modeli import ediyor (`wwdelhi_scaler` modÃ¼lÃ¼nden)
- Yeni bir Ã¶rnek veri oluÅŸturuyor
- Tahmin yapÄ±yor

**Ã–rnek kullanÄ±m:**
```python
new_trip = pd.DataFrame({
    'distance_km': [15.5],              # 15.5 km yol
    'average_speed_kmph': [25.0],       # Ortalama 25 km/h hÄ±z
    'weather_condition': ['Rain'],      # YaÄŸmurlu hava
    'time_of_day': ['Morning Peak'],    # Sabah yoÄŸun saati
    'day_of_week': ['Weekday'],         # Hafta iÃ§i
    'road_type': ['Main Road']          # Ana yol
})
```

**Ã‡Ä±ktÄ±:**
```
Tahmin: High

Ä°htimaller:
  Low: 5.23%
  Medium: 18.67%
  High: 61.45%
  Very High: 14.65%
```

Model ÅŸÃ¶yle diyor: "Bu koÅŸullarda trafik %61 ihtimalle HIGH (yoÄŸun) olacak!"

## NasÄ±l KullanÄ±lÄ±r?

### Gereksinimler

```bash
pip install pandas numpy scikit-learn statsmodels
```

### AdÄ±m 1: Veri setini indir
Kaggle'dan Delhi trafik veri setini indir ve `wwdelhi_traffic.csv` olarak kaydet.

### AdÄ±m 2: Ana modeli Ã§alÄ±ÅŸtÄ±r
```bash
python wwdelhi_scaler.py
```

Bu komut:
- Modeli eÄŸitir
- Performans metriklerini gÃ¶sterir
- Ã–rnek bir tahmin yapar

### AdÄ±m 3: Kendi tahminini yap
```bash
python testing.py
```

Veya `testing.py` iÃ§indeki deÄŸerleri deÄŸiÅŸtirerek kendi senaryolarÄ±nÄ± test et!

### AdÄ±m 4 (Opsiyonel): Ä°statistiksel analiz
```bash
python ww-p-value-delhi.py
```

P-deÄŸerlerini ve katsayÄ±larÄ± gÃ¶rmek iÃ§in.

## Teknik Detaylar

### Veri Ã–n Ä°ÅŸleme

**1. Kategorik DeÄŸiÅŸkenler â†’ Dummy Variables**
```python
# Ã–rnek: weather_condition
# ['Clear', 'Rain', 'Fog'] 
# DÃ¶nÃ¼ÅŸÃ¼r â†’
# weather_condition_Rain: 0 veya 1
# weather_condition_Fog: 0 veya 1
# (Clear: her ikisi de 0 olur - referans kategori)
```

**2. SayÄ±sal DeÄŸiÅŸkenler â†’ Scaling**
```python
# Mesafe: 2.15 km - 26.64 km arasÄ±
# HÄ±z: 7.6 km/h - 68.5 km/h arasÄ±
# BunlarÄ± standartlaÅŸtÄ±r: ortalama=0, std=1
```

**Neden?** Logistic Regression mesafelere karÅŸÄ± hassastÄ±r. 20 km ile 40 km arasÄ±ndaki fark, modelin doÄŸru Ã§alÄ±ÅŸmasÄ± iÃ§in normalize edilmeli.

### Model DeÄŸerlendirme

**Confusion Matrix** - Modelin ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶sterir:
```
              Tahmin
GerÃ§ek    Low  Med  High  VHigh
Low       [120  10   2     0  ]
Medium    [ 15  95  18     1  ]
High      [  3  22  88     5  ]
Very High [  1   2  12    45  ]
```

Her satÄ±r: gerÃ§ek deÄŸer
Her sÃ¼tun: modelin tahmini

**Classification Report** - DetaylÄ± metrikler:
- **Precision**: Modelin "High" dediÄŸi yerlerin kaÃ§Ä± gerÃ§ekten High?
- **Recall**: GerÃ§ek High olanlarÄ±n kaÃ§Ä±nÄ± yakaladÄ±?
- **F1-Score**: Precision ve Recall'un harmonik ortalamasÄ±

### Overfitting KontrolÃ¼

```python
if train_acc - test_acc > 0.10:
    print("WARNING: Overfitting detected.")
```

EÄŸer eÄŸitim verisi Ã¼zerinde Ã§ok baÅŸarÄ±lÄ± ama test verisinde kÃ¶tÃ¼yse â†’ model ezberlemiÅŸx generalleÅŸtirmemiÅŸ demektir!

**Ã‡Ã¶zÃ¼mler:**
- Daha fazla veri topla
- Feature sayÄ±sÄ±nÄ± azalt
- Regularization ekle (L1, L2)
- Cross-validation kullan (zaten yapÄ±yoruz!)

## Ä°puÃ§larÄ± ve Notlar

1. **Rare kategoriler**
   ```python
   rare_weather = df['weather_condition'].value_counts()[
       df['weather_condition'].value_counts() < 5
   ].index
   ```
   5'ten az Ã¶rneÄŸi olan hava durumlarÄ±nÄ± 'Other' yapÄ±yoruz. Neden? Ã‡Ã¼nkÃ¼ model 3-4 Ã¶rnekle Ã¶ÄŸrenemez, sadece ezberler.

2. **Pipeline kullanÄ±mÄ±**
   ```python
   model = Pipeline([
       ('preprocessor', preprocessor),
       ('classifier', LogisticRegression())
   ])
   ```
   Bu Ã§ok temiz bir yaklaÅŸÄ±m! Ã–nce preprocessing, sonra model - her ÅŸey tek bir nesnede.

1. **Yeni veri iÃ§in tahmin yaparken dikkat edin**
   ```python
   # EÄŸitimde olmayan kolonlarÄ± ekle
   for col in X_train.columns:
       if col not in new_trip.columns:
           new_trip[col] = 0
   
   # AynÄ± sÄ±rada kolonlarÄ± dÃ¼zenle. burada Ã§ok sorun yaÅŸamÄ±ÅŸtÄ±m
   new_trip = new_trip[X_train.columns]
   ```
   Bu Ã‡OOK Ã¶nemli! Yoksa model hata verir.

## Ã–ÄŸrenme KaynaklarÄ±

EÄŸer bu konularda daha fazla Ã¶ÄŸrenmek istersen:

- **Pandas**: Veri manipÃ¼lasyonu
- **Scikit-learn**: Makine Ã¶ÄŸrenmesi
- **Logistic Regression**: SÄ±nÄ±flandÄ±rma algoritmasÄ±
- **Feature Engineering**: DeÄŸiÅŸken mÃ¼hendisliÄŸi
- **Cross-Validation**: Model doÄŸrulama teknikleri
- **Confusion Matrix**: Model deÄŸerlendirme


## Lisans

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±nÄ±z.



**Not**: Bu bir eÄŸitim/Ã¶ÄŸrenme projesidir. GerÃ§ek trafik tahminleri iÃ§in daha karmaÅŸÄ±k modeller ve daha fazla veri gerekebilir. 

SorularÄ±nÄ±z veya Ã¶nerileriniz varsa issue aÃ§maktan Ã§ekinmeyin! 
